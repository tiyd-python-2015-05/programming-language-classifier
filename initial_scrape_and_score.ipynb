{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Making the dataframe from RosettaCode using web scraper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scraper import scrape_and_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Using 50 Rosetta Code tasks (e.g. palindrome, hailstone sequence, random numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = scrape_and_clean(num_links=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abap</td>\n",
       "      <td>report z_align no standard page header.start-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada</td>\n",
       "      <td>with Ada.Characters.Latin_1;  use Ada.Characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algol68</td>\n",
       "      <td>STRING nl = REPR 10;STRING text in list := \"Gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autohotkey</td>\n",
       "      <td>lines = (|$|$|$|$|$|$|$|$|$|$|$|Given$a$text$f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>autoit</td>\n",
       "      <td>; == If the given text is in an file, it will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1\n",
       "0        abap  report z_align no standard page header.start-o...\n",
       "1         ada  with Ada.Characters.Latin_1;  use Ada.Characte...\n",
       "2     algol68  STRING nl = REPR 10;STRING text in list := \"Gi...\n",
       "3  autohotkey  lines = (|$|$|$|$|$|$|$|$|$|$|$|Given$a$text$f...\n",
       "4      autoit   ; == If the given text is in an file, it will..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split dataframe to labels and code \n",
    "y = df.loc[:, 0]\n",
    "X = df.loc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruby             82\n",
       "python           76\n",
       "j                76\n",
       "tcl              73\n",
       "c                65\n",
       "lisp             61\n",
       "haskell          57\n",
       "rexx             55\n",
       "html5            54\n",
       "ada              54\n",
       "perl6            52\n",
       "d                52\n",
       "perl             51\n",
       "cpp              48\n",
       "ocaml            40\n",
       "go               40\n",
       "java             39\n",
       "scala            39\n",
       "purebasic        36\n",
       "autohotkey       36\n",
       "groovy           32\n",
       "csharp           31\n",
       "fortran          31\n",
       "lua              30\n",
       "javascript       27\n",
       "clojure          26\n",
       "icon             26\n",
       "php              25\n",
       "algol68          24\n",
       "parigp           23\n",
       "                 ..\n",
       "asm               4\n",
       "xml               4\n",
       "rsplus            3\n",
       "modula2           3\n",
       "cfm               3\n",
       "cmake             3\n",
       "vbnet             3\n",
       "newlisp           3\n",
       "pli               2\n",
       "zxbasic           2\n",
       "actionscript3     2\n",
       "gml               2\n",
       "locobasic         2\n",
       "sas               2\n",
       "lolcode           1\n",
       "sql               1\n",
       "dos               1\n",
       "vim               1\n",
       "freebasic         1\n",
       "asymptote         1\n",
       "gnuplot           1\n",
       "html4strict       1\n",
       "povray            1\n",
       "io                1\n",
       "abap              1\n",
       "logtalk           1\n",
       "visualfoxpro      1\n",
       "make              1\n",
       "bf                1\n",
       "whitespace        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the number of languages in the dataframe\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0          abap\n",
       " 1           ada\n",
       " 2       algol68\n",
       " 3    autohotkey\n",
       " 4        autoit\n",
       " Name: 0, dtype: object, 0    report z_align no standard page header.start-o...\n",
       " 1    with Ada.Characters.Latin_1;  use Ada.Characte...\n",
       " 2    STRING nl = REPR 10;STRING text in list := \"Gi...\n",
       " 3    lines = (|$|$|$|$|$|$|$|$|$|$|$|Given$a$text$f...\n",
       " 4     ; == If the given text is in an file, it will...\n",
       " Name: 1, dtype: object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(),\\\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag_of_words', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe = Pipeline([('bag_of_words', CountVectorizer()),\n",
    "                      ('bayes', MultinomialNB())])\n",
    "nb_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag_of_words', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82278481012658233, 0.44303797468354428)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe.score(X_train, y_train),\\\n",
    "nb_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['python'], \n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing NB with sample text, it guessed right!\n",
    "nb_pipe.predict([\"\"\"def simulation(n=16):\"\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Guessed python correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7cdata',\n",
       " '7d',\n",
       " '7ddata',\n",
       " '7e',\n",
       " '7edata',\n",
       " '7f',\n",
       " '7print',\n",
       " '7puts',\n",
       " '7s',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '800set',\n",
       " '802',\n",
       " '809017j0',\n",
       " '809017j_0',\n",
       " '80data',\n",
       " '81',\n",
       " '814',\n",
       " '8167',\n",
       " '81attributeerror',\n",
       " '81traceback',\n",
       " '82',\n",
       " '82data',\n",
       " '83',\n",
       " '832040',\n",
       " '83292',\n",
       " '83data',\n",
       " '84',\n",
       " '84data',\n",
       " '85',\n",
       " '85set',\n",
       " '86',\n",
       " '86267571272ull',\n",
       " '866025403784439i',\n",
       " '86data',\n",
       " '87',\n",
       " '87684',\n",
       " '876s',\n",
       " '87data',\n",
       " '88',\n",
       " '8859',\n",
       " '88data',\n",
       " '89',\n",
       " '899',\n",
       " '89data',\n",
       " '8a',\n",
       " '8adata',\n",
       " '8adjoin',\n",
       " '8and',\n",
       " '8apply',\n",
       " '8b',\n",
       " '8bdata',\n",
       " '8c',\n",
       " '8carpet',\n",
       " '8carpet_to_string',\n",
       " '8cdata',\n",
       " '8d',\n",
       " '8ddata',\n",
       " '8e',\n",
       " '8edata',\n",
       " '8equal',\n",
       " '8f',\n",
       " '8ff',\n",
       " '8fn',\n",
       " '8for_each_in_range',\n",
       " '8g',\n",
       " '8i',\n",
       " '8if',\n",
       " '8in_carpet',\n",
       " '8is_0',\n",
       " '8j',\n",
       " '8let',\n",
       " '8lets',\n",
       " '8n',\n",
       " '8nil',\n",
       " '8not',\n",
       " '8or',\n",
       " '8p',\n",
       " '8pair',\n",
       " '8plus',\n",
       " '8pow',\n",
       " '8print',\n",
       " '8px',\n",
       " '8q',\n",
       " '8quotient',\n",
       " '8r',\n",
       " '8remainder',\n",
       " '8s',\n",
       " '8seq_fold',\n",
       " '8seq_iota',\n",
       " '8seq_map',\n",
       " '8space',\n",
       " '8t',\n",
       " '8th',\n",
       " '8true',\n",
       " '8x',\n",
       " '8y',\n",
       " '90',\n",
       " '900',\n",
       " '9000',\n",
       " '90122',\n",
       " '9056',\n",
       " '906',\n",
       " '9080',\n",
       " '90data',\n",
       " '91',\n",
       " '913',\n",
       " '91526',\n",
       " '91data',\n",
       " '92',\n",
       " '9227465',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '951057',\n",
       " '956722026041ull',\n",
       " '96',\n",
       " '97',\n",
       " '978',\n",
       " '97data',\n",
       " '98',\n",
       " '987',\n",
       " '99',\n",
       " '999',\n",
       " '9999',\n",
       " '99999',\n",
       " '999999',\n",
       " '999999999',\n",
       " '9999cc',\n",
       " '99_999',\n",
       " '99cc99',\n",
       " '99set',\n",
       " '9_',\n",
       " '9a',\n",
       " '9b',\n",
       " '9bdata',\n",
       " '9c',\n",
       " '9d',\n",
       " '9e',\n",
       " '9edata',\n",
       " '9f',\n",
       " '9let',\n",
       " '9s',\n",
       " '9th',\n",
       " '9y',\n",
       " '_0',\n",
       " '_1',\n",
       " '_2',\n",
       " '__',\n",
       " '___',\n",
       " '____',\n",
       " '_____',\n",
       " '______',\n",
       " '_______',\n",
       " '________',\n",
       " '_________',\n",
       " '__________',\n",
       " '____________',\n",
       " '_____________',\n",
       " '______________',\n",
       " '_______________',\n",
       " '________________________',\n",
       " '________________________________',\n",
       " '_____________________________________________________',\n",
       " '________july___________________august_________________september_____',\n",
       " '_______april____________________may____________________june________',\n",
       " '______january_________________february_________________march_______',\n",
       " '______october_________________november________________december______',\n",
       " '__add',\n",
       " '__addfunction',\n",
       " '__call',\n",
       " '__class',\n",
       " '__concat',\n",
       " '__construct',\n",
       " '__curry',\n",
       " '__data__baker',\n",
       " '__defaultmaxsize__',\n",
       " '__div',\n",
       " '__dmain',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__func__',\n",
       " '__future__',\n",
       " '__index',\n",
       " '__init__',\n",
       " '__main__',\n",
       " '__method__',\n",
       " '__mul',\n",
       " '__name__',\n",
       " '__new',\n",
       " '__new__',\n",
       " '__newindex',\n",
       " '__optuncall',\n",
       " '__package__',\n",
       " '__printon',\n",
       " '__repr__',\n",
       " '__sub',\n",
       " '__tostring',\n",
       " '__unm',\n",
       " '__va_args__',\n",
       " '_angle',\n",
       " '_ant',\n",
       " '_antstate',\n",
       " '_arraydisplay',\n",
       " '_asdict',\n",
       " '_bar',\n",
       " '_bmp',\n",
       " '_bonk',\n",
       " '_carpet',\n",
       " '_clr_ps_',\n",
       " '_cls',\n",
       " '_columns_',\n",
       " '_createcalendar',\n",
       " '_d',\n",
       " '_data',\n",
       " '_dateisleapyear',\n",
       " '_datetodayofweekiso',\n",
       " '_dummy',\n",
       " '_es_number',\n",
       " '_f',\n",
       " '_facing',\n",
       " '_fb',\n",
       " '_fc',\n",
       " '_ff',\n",
       " '_file',\n",
       " '_fm',\n",
       " '_foo',\n",
       " '_fs',\n",
       " '_getaligned',\n",
       " '_gost32',\n",
       " '_grid',\n",
       " '_hinst',\n",
       " '_hwnd',\n",
       " '_i',\n",
       " '_ialign',\n",
       " '_ilen',\n",
       " '_imaxlen',\n",
       " '_import',\n",
       " '_inst',\n",
       " '_iterlen',\n",
       " '_iyear',\n",
       " '_langtons_ant_',\n",
       " '_lstatus',\n",
       " '_matrix_h',\n",
       " '_max',\n",
       " '_merge',\n",
       " '_mh',\n",
       " '_mw']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we wnat to see what the vector features look like \n",
    "#make a new vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train, y_train)\n",
    "vectorizer.get_feature_names()[1000:1250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Remvoing the languages with the least amount of examples to see if the predictions increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruby          82\n",
       "python        76\n",
       "j             76\n",
       "tcl           73\n",
       "c             65\n",
       "lisp          61\n",
       "haskell       57\n",
       "rexx          55\n",
       "ada           54\n",
       "html5         54\n",
       "d             52\n",
       "perl6         52\n",
       "perl          51\n",
       "cpp           48\n",
       "ocaml         40\n",
       "go            40\n",
       "scala         39\n",
       "java          39\n",
       "autohotkey    36\n",
       "purebasic     36\n",
       "groovy        32\n",
       "csharp        31\n",
       "fortran       31\n",
       "lua           30\n",
       "javascript    27\n",
       "icon          26\n",
       "clojure       26\n",
       "php           25\n",
       "algol68       24\n",
       "parigp        23\n",
       "delphi        22\n",
       "matlab        22\n",
       "fsharp        22\n",
       "oz            21\n",
       "bash          21\n",
       "lb            20\n",
       "smalltalk     20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If the language does not have 20 code examples we are deleting it from the dataframe\n",
    "new_df = df.groupby(0).filter(lambda x: len(x) >= 20)\n",
    "new_df[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80028129395218006, 0.51265822784810122)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Re-testing with MultinomialNB\n",
    "new_y = df.loc[:, 0]\n",
    "new_X = df.loc[:, 1]\n",
    "#splitting data\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y)\n",
    "#running pipe to vectorize and run Multinomial\n",
    "new_nb_pipe = Pipeline([('bag_of_words', CountVectorizer()),\n",
    "                      ('bayes', MultinomialNB())])\n",
    "#fitting \n",
    "new_nb_pipe.fit(new_X_train, new_y_train)\n",
    "#checking score\n",
    "new_nb_pipe.score(new_X_train, new_y_train),\\\n",
    "new_nb_pipe.score(new_X_test, new_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###A little better, test score increased by 10%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now on to testing with BIGGER dataframe. See the big_scrape_and_score notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Beacuse only including only the langagues  with the most example code impoves the score I changed/improved the function that creates the dataframe to now include a cut off for number of languages. The cut off value is now passed in as an arugment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###I also created a function the runs the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
